# Предсказание выживания пассажиров Титаника

## Описание проекта

Крушение «Титаника» — одно из самых печально известных кораблекрушений в истории. 15 апреля 1912 года во время своего первого рейса «Титаник», считавшийся «непотопляемым», затонул после столкновения с айсбергом. К сожалению, спасательных шлюпок на всех на борту не хватило, в результате чего из 2224 пассажиров и членов экипажа погибли 1502 человека. Хотя в выживании был некоторый элемент удачи, кажется, что у некоторых групп людей было больше шансов выжить, чем у других. В этом исследовании мы построим прогностическую модель, отвечающую на вопрос: «У каких людей больше шансов выжить?», используя данные о пассажирах (например, имя, возраст, пол, социально-экономический класс и т.д.).

## Данные

В наличии были следующие данные:

Тренировочный набор и тестовый набор. Оба набора содержат следующие колонки:
- идентификационный номер пассажира
- выживание
- класс билета
- имя
- пол
- возраст в годах
- братьев и сестер/супругов на борту Титаника
- родителей/детей на борту Титаника
- номер билета
- пассажирский тариф
- номер каюты
- порт погрузки

## Задача
 
Построить модель предсказания выживания пассажиров.

## Используемые библиотеки
*pandas, numpy, matplotlib, seaborn, sklearn, lightgbm, catboost, xgboost*

## Выводы

Данные уже разделены были на обучающую и тестовую выборки. Обе выборки содержали пропуски в колонках `Cabin` (около 80%) и `Age` (около 20%). Менее 1% пропусков в колонке `Embarked` обучающей выборки. И менее 1% пропусков в колонке `Fare` тестовой выборки. В обучающей выборке был небольшой дисбаланс классов: почти 40% выживших. Анализ данных показал, что у женщин и у людей из 1 класса несколько больше шансов выжить. Матрица корреляции признаков это подтвердила. Пропуски возраста в обучающей и тестовой выборках заполнили медианными значениями обучающей выборки с группировкой по полу. Пропуск в колонке `Fare` тестовой выборки заполнили медианой обучающей выборки с группировкой по классу билета. От пропусков в колонке `Cabin` избавились, просто удалив колонку: там пропосков слишком много. Также удалили столбцы `PassengerId`, `Name` и `Ticket` как бесполезные. Сделали перекодировку категориальных переменных для подготовки данных к обучению. Обучили и сравнили модели Дерева решений, Случайного леса, Логистической регрессии,  Стохастического градиентного спуска, LightGBM, CatBoost, XGBoost, Глупую модель. Лучшей оказалась модель **LightGBM** (F1 = 0.77, Accuracy = 0.83). Точность на тестовой выборке 0.77. Наиболее важными признаками для предсказания выживания пассажиров оказались пассажирский тариф, возраст, число братьев/сестер/супругов на борту, пол. Проект завершён.